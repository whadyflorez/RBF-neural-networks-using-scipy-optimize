# RBF-neural-networks-using-scipy-optimize
RBF neural networks using scipy optimize
ML does not depend on pytorch neither on TF or anything similar. ML is a series of nunmerical and computational techniques based on data to solve many problems of different kinds. It should nnot be considered a separate science of its own.
RBF networks requiere special training algorithms that are not always the same as deep NN.

https://datascience.stackexchange.com/questions/44324/how-to-get-out-of-local-minimums-on-stochastic-gradient-descent
https://arxiv.org/abs/2208.00441
https://arxiv.org/abs/2105.14694
https://maths-people.anu.edu.au/~brent/pub/pub011.html
https://math.stackexchange.com/questions/2349026/why-is-the-approximation-of-hessian-jtj-reasonable
https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm
https://www.mdpi.com/2076-3417/10/6/2036
https://arxiv.org/pdf/1905.06738.pdf
 
https://doi.org/10.3390/electronics9111809
https://link.springer.com/article/10.1007/s10898-022-01205-4
https://www.sciencedirect.com/science/article/pii/S0893608020303579

Why should you have special training of RBF NN? "In this article, we describe a modern gradient-based RBFN implementation based on the same computational machinery that is used in modern deep learning. While gradient-based methods for training RBFNâ€™s have been criticized (Chen, Cowan, & Grant, 1991) because of local optima, tailored training methods have been used in the past with good results"


