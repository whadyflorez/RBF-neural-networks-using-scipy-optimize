{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmlEBFm-DplN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como definir un problema en pytorch sin usar classes"
      ],
      "metadata": {
        "id": "YvaIOHCNDrz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXfdKIey9mOc",
        "outputId": "ae950f3f-7eb5-4882-869b-44da5bc90a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/200], Loss: 0.7478073239326477\n",
            "Epoch [20/200], Loss: 0.2538773715496063\n",
            "Epoch [30/200], Loss: 0.07556147128343582\n",
            "Epoch [40/200], Loss: 0.01932181976735592\n",
            "Epoch [50/200], Loss: 0.00405034190043807\n",
            "Epoch [60/200], Loss: 0.0006382136489264667\n",
            "Epoch [70/200], Loss: 8.205812628148124e-05\n",
            "Epoch [80/200], Loss: 3.938790177926421e-05\n",
            "Epoch [90/200], Loss: 3.848583946819417e-05\n",
            "Epoch [100/200], Loss: 2.7724838219000958e-05\n",
            "Epoch [110/200], Loss: 1.5634976080036722e-05\n",
            "Epoch [120/200], Loss: 7.470439868484391e-06\n",
            "Epoch [130/200], Loss: 3.164819872836233e-06\n",
            "Epoch [140/200], Loss: 1.2282999932722305e-06\n",
            "Epoch [150/200], Loss: 4.4860919956590806e-07\n",
            "Epoch [160/200], Loss: 1.598371994759873e-07\n",
            "Epoch [170/200], Loss: 5.812311698605299e-08\n",
            "Epoch [180/200], Loss: 2.2797792098572245e-08\n",
            "Epoch [190/200], Loss: 9.866293559923633e-09\n",
            "Epoch [200/200], Loss: 4.5815986560171496e-09\n",
            "Predicciones después del entrenamiento:\n",
            "Entrada: 1.0, Predicción: 2.000088930130005, Valor real: 2.0\n",
            "Entrada: 2.0, Predicción: 4.0000081062316895, Valor real: 4.0\n",
            "Entrada: 3.0, Predicción: 5.999927043914795, Valor real: 6.0\n",
            "Entrada: 4.0, Predicción: 7.9998459815979, Valor real: 8.0\n",
            "Entrada: 5.0, Predicción: 9.999764442443848, Valor real: 10.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Función para definir el modelo\n",
        "def simple_model(x, weights, bias):\n",
        "    return torch.matmul(x, weights) + bias\n",
        "\n",
        "# Función de pérdida personalizada\n",
        "def custom_loss(y_pred, y_true):\n",
        "    return torch.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "# Función para calcular los gradientes manualmente de forma analítica\n",
        "def calculate_gradients(x, y, weights, bias):\n",
        "    with torch.no_grad():\n",
        "        gradient = torch.mean(2 * (simple_model(x, weights, bias) - y) * x, dim=0)\n",
        "        bias_gradient = torch.mean(2 * (simple_model(x, weights, bias) - y))\n",
        "\n",
        "    return gradient, bias_gradient\n",
        "\n",
        "# Inicializar los parámetros del modelo\n",
        "weights = torch.randn(1, 1, requires_grad=True)\n",
        "bias = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Datos de ejemplo\n",
        "x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0], [8.0], [10.0]])\n",
        "\n",
        "# Definir el optimizador\n",
        "#optimizer = optim.SGD([weights, bias], lr=0.1)\n",
        "optimizer = optim.SGD([weights, bias], lr=0.01, momentum=0.9)\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "epochs = 200\n",
        "batch_size = 3\n",
        "num_batches = len(x_train) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Iterar sobre los lotes de datos\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "\n",
        "        # Obtener el lote actual\n",
        "        x_batch = x_train[start_idx:end_idx]\n",
        "        y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "        # Paso de adelante: Calcular la predicción y la pérdida\n",
        "        y_pred = simple_model(x_batch, weights, bias)\n",
        "        loss = custom_loss(y_pred, y_batch)\n",
        "\n",
        "        # Calcular los gradientes manualmente de forma analítica\n",
        "        weight_gradient, bias_gradient = calculate_gradients(x_batch, y_batch, weights, bias)\n",
        "\n",
        "        # Actualizar los parámetros del modelo utilizando el optimizador\n",
        "        optimizer.zero_grad()\n",
        "        weights.grad = weight_gradient.reshape_as(weights)\n",
        "        bias.grad = bias_gradient.reshape_as(bias)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Imprimir la pérdida\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
        "\n",
        "# Evaluar el modelo entrenado\n",
        "with torch.no_grad():\n",
        "    print(\"Predicciones después del entrenamiento:\")\n",
        "    y_pred = simple_model(x_train, weights, bias)\n",
        "    for i, (predicted, true) in enumerate(zip(y_pred, y_train)):\n",
        "        print(f'Entrada: {x_train[i].item()}, Predicción: {predicted.item()}, Valor real: {true.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como usar LBFGS full batch"
      ],
      "metadata": {
        "id": "R5vkMsnnEARH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Función para definir el modelo\n",
        "def simple_model(x, weights, bias):\n",
        "    return torch.matmul(x, weights) + bias\n",
        "\n",
        "# Función de pérdida personalizada\n",
        "def custom_loss(y_pred, y_true):\n",
        "    return torch.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "# Función para calcular los gradientes manualmente de forma analítica\n",
        "def calculate_gradients(x, y, weights, bias):\n",
        "    with torch.no_grad():\n",
        "        gradient = torch.mean(2 * (simple_model(x, weights, bias) - y) * x, dim=0)\n",
        "        bias_gradient = torch.mean(2 * (simple_model(x, weights, bias) - y))\n",
        "\n",
        "    return gradient, bias_gradient\n",
        "\n",
        "# Inicializar los parámetros del modelo\n",
        "weights = torch.randn(1, 1, requires_grad=True)\n",
        "bias = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Datos de ejemplo\n",
        "x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0], [8.0], [10.0]])\n",
        "\n",
        "# Definir el optimizador LBFGS\n",
        "optimizer = optim.LBFGS([weights, bias], lr=0.1)\n",
        "\n",
        "# Función para realizar un paso de optimización con LBFGS\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = simple_model(x_train, weights, bias)\n",
        "    loss = custom_loss(y_pred, y_train)\n",
        "\n",
        "    # Calcular los gradientes manualmente\n",
        "    weight_gradient, bias_gradient = calculate_gradients(x_train, y_train, weights, bias)\n",
        "\n",
        "    # Asignar los gradientes calculados manualmente\n",
        "    weights.grad = weight_gradient.reshape_as(weights)\n",
        "    bias.grad = bias_gradient.reshape_as(bias)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.step(closure)\n",
        "\n",
        "    # Imprimir la pérdida\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            loss = closure()\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
        "\n",
        "# Evaluar el modelo entrenado\n",
        "with torch.no_grad():\n",
        "    print(\"Predicciones después del entrenamiento:\")\n",
        "    y_pred = simple_model(x_train, weights, bias)\n",
        "    for i, (predicted, true) in enumerate(zip(y_pred, y_train)):\n",
        "        print(f'Entrada: {x_train[i].item()}, Predicción: {predicted.item()}, Valor real: {true.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu0NTXnrDIpm",
        "outputId": "ce26e68e-5d5f-4ce9-d18a-29fd2f7c4265"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.8604737750393952e-09\n",
            "Epoch [20/100], Loss: 4.32783059389763e-10\n",
            "Epoch [30/100], Loss: 4.32783059389763e-10\n",
            "Epoch [40/100], Loss: 4.32783059389763e-10\n",
            "Epoch [50/100], Loss: 4.32783059389763e-10\n",
            "Epoch [60/100], Loss: 4.32783059389763e-10\n",
            "Epoch [70/100], Loss: 4.32783059389763e-10\n",
            "Epoch [80/100], Loss: 4.32783059389763e-10\n",
            "Epoch [90/100], Loss: 4.32783059389763e-10\n",
            "Epoch [100/100], Loss: 4.32783059389763e-10\n",
            "Predicciones después del entrenamiento:\n",
            "Entrada: 1.0, Predicción: 2.000035285949707, Valor real: 2.0\n",
            "Entrada: 2.0, Predicción: 4.000025272369385, Valor real: 4.0\n",
            "Entrada: 3.0, Predicción: 6.0000152587890625, Valor real: 6.0\n",
            "Entrada: 4.0, Predicción: 8.000005722045898, Valor real: 8.0\n",
            "Entrada: 5.0, Predicción: 9.999996185302734, Valor real: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como usar LBFGS en batches"
      ],
      "metadata": {
        "id": "Ogd-_EqdEX4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Función para definir el modelo\n",
        "def simple_model(x, weights, bias):\n",
        "    return torch.matmul(x, weights) + bias\n",
        "\n",
        "# Función de pérdida personalizada\n",
        "def custom_loss(y_pred, y_true):\n",
        "    return torch.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "# Función para calcular los gradientes manualmente de forma analítica\n",
        "def calculate_gradients(x, y, weights, bias):\n",
        "    with torch.no_grad():\n",
        "        gradient = torch.mean(2 * (simple_model(x, weights, bias) - y) * x, dim=0)\n",
        "        bias_gradient = torch.mean(2 * (simple_model(x, weights, bias) - y))\n",
        "\n",
        "    return gradient, bias_gradient\n",
        "\n",
        "# Inicializar los parámetros del modelo\n",
        "weights = torch.randn(1, 1, requires_grad=True)\n",
        "bias = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Datos de ejemplo\n",
        "x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])\n",
        "y_train = torch.tensor([[2.0], [4.0], [6.0], [8.0], [10.0]])\n",
        "\n",
        "# Definir el optimizador LBFGS\n",
        "optimizer = optim.LBFGS([weights, bias], lr=0.01)\n",
        "\n",
        "# Función para realizar un paso de optimización con LBFGS\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    total_loss = 0\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        y_pred = simple_model(x_batch, weights, bias)\n",
        "        loss = custom_loss(y_pred, y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calcular los gradientes manualmente\n",
        "        weight_gradient, bias_gradient = calculate_gradients(x_batch, y_batch, weights, bias)\n",
        "\n",
        "        # Asignar los gradientes calculados manualmente\n",
        "        weights.grad = weight_gradient.reshape_as(weights)\n",
        "        bias.grad = bias_gradient.reshape_as(bias)\n",
        "\n",
        "    # Retornar el total de la pérdida para el cálculo de la media\n",
        "    return total_loss / len(x_train)\n",
        "\n",
        "# Ciclo de entrenamiento\n",
        "epochs = 100\n",
        "batch_size = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.step(closure)\n",
        "\n",
        "    # Imprimir la pérdida\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            loss = closure()\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss}')\n",
        "\n",
        "# Evaluar el modelo entrenado\n",
        "with torch.no_grad():\n",
        "    print(\"Predicciones después del entrenamiento:\")\n",
        "    y_pred = simple_model(x_train, weights, bias)\n",
        "    for i, (predicted, true) in enumerate(zip(y_pred, y_train)):\n",
        "        print(f'Entrada: {x_train[i].item()}, Predicción: {predicted.item()}, Valor real: {true.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc41w8OODi2y",
        "outputId": "2ad42fe1-547a-4a24-8193-c01f36378ec9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.658161497116089\n",
            "Epoch [20/100], Loss: 0.15399158596992493\n",
            "Epoch [30/100], Loss: 0.06731706149876118\n",
            "Epoch [40/100], Loss: 0.0015108366613276302\n",
            "Epoch [50/100], Loss: 2.5963342795876088e-05\n",
            "Epoch [60/100], Loss: 4.7185599214571996e-07\n",
            "Epoch [70/100], Loss: 4.678699667692854e-08\n",
            "Epoch [80/100], Loss: 3.849015399737254e-08\n",
            "Epoch [90/100], Loss: 3.1645950571146384e-08\n",
            "Epoch [100/100], Loss: 2.6175644052273128e-08\n",
            "Predicciones después del entrenamiento:\n",
            "Entrada: 1.0, Predicción: 1.9995261430740356, Valor real: 2.0\n",
            "Entrada: 2.0, Predicción: 3.9996628761291504, Valor real: 4.0\n",
            "Entrada: 3.0, Predicción: 5.999799728393555, Valor real: 6.0\n",
            "Entrada: 4.0, Predicción: 7.999936580657959, Valor real: 8.0\n",
            "Entrada: 5.0, Predicción: 10.00007438659668, Valor real: 10.0\n"
          ]
        }
      ]
    }
  ]
}